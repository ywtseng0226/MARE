# @package _global_

optimizer:
  type: AdamW
  lr: 1.0e-4
  weight_decay: 1.0e-4
  # paramwise_cfg:
  #   - name: backbone
  #     lr_mult: 0.1
scheduler:
  type: MultiStepLR
  milestones: [25]
  gamma: 0.1

trainer:
  max_epochs: 30
